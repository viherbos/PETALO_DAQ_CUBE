{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from SimLib import config_sim as conf\n",
    "from SimLib import sipm_mapping as DAQ\n",
    "import sys\n",
    "#sys.path.append(\"/home/viherbos/GITHUB/PETALO_analysis\")\n",
    "import fit_library\n",
    "import scipy.signal as sc\n",
    "import itertools as it\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from antea.reco.reco_functions import find_first_interactions_in_active as antea_ffia\n",
    "#import TOF_library as T_lib\n",
    "%matplotlib nbagg\n",
    "%reload_ext autoreload\n",
    "%autoreload 2   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "class MOVIE(object):\n",
    "    \"\"\" Create a movie-like register of the gamma1+gamma2 TRUE events\n",
    "    \"\"\"\n",
    "    def __init__(self, path, filename, SiPM):\n",
    "        \"\"\" path and filename of .h5 data file\n",
    "            SiPM = [first_sipm, n_sipms]\n",
    "        \"\"\"\n",
    "        file = path + filename\n",
    "        particles = pd.read_hdf(file,key='MC/particles')\n",
    "        hits      = pd.read_hdf(file,key='MC/hits')\n",
    "        self.keys_particles = particles.columns\n",
    "        self.keys_hits      = hits.columns\n",
    "        self.particles      = particles\n",
    "        self.hits           = hits\n",
    "        self.tof_wave       = np.array(pd.read_hdf(file,key='MC/tof_waveforms'))\n",
    "        self.n_sipms        = SiPM['n_sipms']\n",
    "        self.first_sipm     = SiPM['first_sipm']    \n",
    "        \n",
    "        json_path         = \"/volumedisk0/home/viherbos/DAQ_data/\"\n",
    "        json_filename     = \"CUBE\"\n",
    "        SIM_CONT          = conf.SIM_DATA(filename=json_path+json_filename+\".json\",read=True)\n",
    "        data              = SIM_CONT.data\n",
    "        L1_Slice, Matrix_I, Matrix_O, topo = DAQ.SiPM_Mapping(data,data['L1']['map_style'])\n",
    "        self.Matrix_O     = Matrix_O\n",
    "        \n",
    "    def true_info(self,event):\n",
    "        \"\"\" Gets data from given event\n",
    "        \"\"\"\n",
    "        particles_i = self.particles[self.particles.event_id==event]\n",
    "        hits_i      = self.hits[self.hits.event_id==event]\n",
    "        return antea_ffia(particles_i, hits_i)\n",
    "    \n",
    "    def process_event(self,event, acc_time):\n",
    "        \"\"\" acc_time: Length of Sliding Window Filter (in time_bins)\n",
    "        \"\"\"\n",
    "        event_select    = np.argwhere(self.tof_wave[:,0]==event)\n",
    "        event_tof       = self.tof_wave[event_select[:,0],1:]\n",
    "        event_tof[:,0]  = event_tof[:,0]*-1-self.first_sipm\n",
    "        # SiPM  |  Timebin  |  Charge\n",
    "\n",
    "        time_length = np.max(event_tof[:,1])\n",
    "        pe_table = np.zeros((time_length+1,self.n_sipms))\n",
    "        \n",
    "        for i in range(event_tof.shape[0]):\n",
    "            pe_table[event_tof[i,1],event_tof[i,0]] = event_tof[i,2]\n",
    "        \n",
    "        T_photon_event = np.sum(pe_table,axis=1)\n",
    "        # Sliding Window over Total Photons(time) for this event (computes slope of photon signal)\n",
    "        \n",
    "        slope          = np.convolve(T_photon_event,np.ones(acc_time))\n",
    "        max_slope_time = np.argmax(slope) \n",
    "        # time of max arrival of photons/acc_time\n",
    "                \n",
    "        photon_acc  = np.cumsum(pe_table,axis=0)\n",
    "        \n",
    "        # We get the accumulated photons in to moments, highest gradient of photons and final photo\n",
    "        #true_data = np.hstack([event,np.array(self.true_info(event))])\n",
    "        #info1 = np.hstack([true_data, photon_acc[max_slope_time,:]])\n",
    "        #info2 = np.hstack([true_data, photon_acc[-1,:]])\n",
    "        \n",
    "        event_info = np.vstack([photon_acc[max_slope_time,:],photon_acc[-1,:]])\n",
    "        \n",
    "        return event_info   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "i = 0\n",
    "name = \"petit_ring_tof_all_tables\"\n",
    "path = \"/volumedisk0/home/paolafer/vicente/\"\n",
    "file_name= name + \".\"+str(i).zfill(3)+\".pet.h5\"\n",
    "i=0\n",
    "A = MOVIE(path,file_name,{'first_sipm':1000,'n_sipms':3500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:IC3.5]",
   "language": "python",
   "name": "conda-env-IC3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
